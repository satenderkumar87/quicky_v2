
# üß† AI-Powered UI Generator

This project converts **UI screenshots and design descriptions** into **production-ready ReactJS UIs** using AI. The system uses OpenAI for layout reasoning, component generation, and professional UI assumptions when input is incomplete.

---

## üöÄ Features

- üñºÔ∏è Image-to-Layout Extraction from one or more UI screenshots
- üß† OpenAI LLM Orchestration (GPT-4 / GPT-3.5)
- ‚öõÔ∏è Code Generation (ReactJS + TailwindCSS + Radix UI)
- üåê Local Hosting with Vite Dev Server
- üîÄ Assumption-based UI Completion with professional layouting
- üëÅÔ∏è Preview of all generated screens, even if unrelated

---

## üìÅ Folder Structure

```
ai-ui-generator/
‚îÇ
‚îú‚îÄ‚îÄ agent/
‚îÇ   ‚îú‚îÄ‚îÄ vision.py             # Extract UI layout from images
‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.py       # LLM-based layout-to-code generation
‚îÇ   ‚îú‚îÄ‚îÄ codegen.py            # Convert layout JSON to React components
‚îÇ   ‚îî‚îÄ‚îÄ builder.py            # Coordinates multi-file input workflow
‚îÇ
‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îî‚îÄ‚îÄ react_component.jinja # HTML/JSX template
‚îÇ
‚îú‚îÄ‚îÄ input/
‚îÇ   ‚îú‚îÄ‚îÄ screen1.png
‚îÇ   ‚îú‚îÄ‚îÄ screen2.jpg
‚îÇ   ‚îú‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ project_description.txt  # Design and functionality intent
‚îÇ
‚îú‚îÄ‚îÄ generated_project/        # Final React app ready to preview
‚îÇ
‚îú‚îÄ‚îÄ main.py                   # Entrypoint script
‚îî‚îÄ‚îÄ requirements.txt
```

---

## üì∏ Input Requirements

- **Screenshots**: One or more `.png`, `.jpg`, or `.jpeg` files in the `input/` directory.
- **Project Description**: `project_description.txt` describing the project‚Äôs goals, target audience, and any known design/system requirements.

> üìå If some screens are unrelated or minimal in detail, the LLM will assume relationships and generate consistent, professional UI screens.

---

## ü§ñ How It Works

1. **Image Parsing** (`vision.py`)
   - Detect layout blocks in multiple images using YOLOv8 / LayoutParser.
   - OCR (PaddleOCR/Tesseract) extracts any visible text.

2. **Layout JSON Generation**
   - All detected UI elements from each screen are converted into layout JSON.
   - Screens are treated independently if no link is found; otherwise, relationships are inferred.

3. **AI Orchestration** (`orchestrator.py`)
   - Sends layout + description to OpenAI.
   - Prompts guide the model to generate:
     - JSX/Tailwind for each screen
     - Radix UI components
     - Routing and reusable components
     - Professional assumptions to fill missing context

4. **Code Generation** (`codegen.py`)
   - Each screen is compiled into a full-page React component.
   - Output includes routing, reusable layouts, and responsive design.

5. **Hosting** (`vite`)
   - Final app is served locally with Vite dev server.
   - Navigate between screens using a pre-built navigation menu.

---

## üß∞ Technologies Used

| Area              | Tech Used                                  |
|-------------------|---------------------------------------------|
| AI / LLM          | OpenAI GPT-4 / GPT-3.5                      |
| Image Processing  | OpenCV, PaddleOCR, LayoutParser             |
| Code Generation   | Python, Jinja2                              |
| Frontend          | ReactJS, TailwindCSS, Radix UI, Vite        |
| Orchestration     | Custom Python agent with OpenAI SDK         |

---

## ‚öôÔ∏è Prerequisites

- Python 3.9+
- Node.js (for Vite dev server)
- OpenAI API Key
- Pip packages (see `requirements.txt`)

---

## üß™ Example Prompt (used by the agent)

```plaintext
You are a frontend engineer. Generate production-ready ReactJS components using Tailwind CSS and Radix UI from the following layout and design context:

Layout JSON (screen 1):
[
  { "type": "input", "label": "Email" },
  { "type": "button", "text": "Subscribe" }
]

Layout JSON (screen 2):
[
  { "type": "navbar", "items": ["Home", "Login", "Dashboard"] },
  { "type": "card", "title": "User Profile" }
]

Project Description:
"A responsive web app for newsletter signup and profile viewing. Should be minimal, professional, mobile-first, using Radix UI and Tailwind."
```

---

## üñ•Ô∏è Run Locally

```bash
git clone https://github.com/yourname/ai-ui-generator
cd ai-ui-generator

# Install Python packages
pip install -r requirements.txt

# Set your OpenAI key
export OPENAI_API_KEY=your-key-here

# Run the generator
python main.py

# Start local Vite dev server (after generation)
cd generated_project
npm install
npm run dev
```

---

## üß© Best Practices

- Group images by feature/page to keep visual coherence
- Keep filenames descriptive (e.g., `login_screen.png`, `profile_view.jpg`)
- Use concise, goal-driven descriptions to guide the LLM
- Define preferred stack (e.g., **Radix UI**, **Chakra**, or **Tailwind**) in `project_description.txt`
- Ensure generated components follow accessibility standards (Radix is ARIA-friendly)
- Use Tailwind utility classes for rapid responsive design
- Review and customize Jinja2 templates to fit project conventions

---

## üìå Future Enhancements

- [ ] Add visual editor for post-generation tweaks
- [ ] Multi-step form recognition
- [ ] Figma API integration
- [ ] Export to other frameworks (Vue, Angular)

---

## üìÑ License

MIT
